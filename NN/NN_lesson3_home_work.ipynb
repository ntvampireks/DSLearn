{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4b1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21cc1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyper params\n",
    "num_epoch = 5\n",
    "cuda_device = -1\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#model\n",
    "#Линейный энкодер\n",
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.15)\n",
    "        self.linear3 = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.activation(self.linear1(x)))\n",
    "        x = self.dropout2(self.activation(self.linear2(x)))\n",
    "        x = self.activation(self.linear3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # encoder_out -> hidden -> 28*28\n",
    "    def __init__(self, latent_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.15)\n",
    "        self.linear3 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.activation(self.linear1(x)))\n",
    "        x = self.dropout2(self.activation(self.linear2(x)))\n",
    "        x = self.activation(self.linear3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ClassicAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, enc_hidden_dim, dec_hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, enc_hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, dec_hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "# model\n",
    "model = ClassicAutoEncoder(28*28, 200, 300, 32)\n",
    "model.train()\n",
    "model.to(device)\n",
    "# result = model(test_tersor)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#lr scheduler\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('C:\\\\Users\\\\Vampire\\\\Repos\\\\NN_reload_stream2', download=True)\n",
    "\n",
    "#loss\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9bfcd89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 0\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 1\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 3\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 4\n"
     ]
    }
   ],
   "source": [
    "#dataloder\n",
    "for epoch in range(num_epoch):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).view(batch['data'].size(0), -1)\n",
    "        optim.zero_grad()\n",
    "        predict = model(data)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    print(f'epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a0d4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33676\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test = dataset.data[255].view(1,-1).long() / 255\n",
    "    test = test.to(device)\n",
    "    #print(test.device)\n",
    "    predict = model(test)\n",
    "    test = test[0].view(28, 28).detach().cpu().numpy()\n",
    "    print((test*255).astype(int).sum())\n",
    "   \n",
    " #   plt.imshow(test)\n",
    " #   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988873b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(predict[0].view(28, 28).cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53a84fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyper params\n",
    "num_epoch = 20\n",
    "cuda_device = -1\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# conv autoencoder\n",
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, in_chan, hidden_ch, out_channels):\n",
    "        super().__init__()\n",
    "        #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=5, stride=1, padding=2) # 28 x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 14 x 14 пулинг размером 2x2 уменьшает размерность в два раза\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 7 x 7\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): # -> 7x7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.pool2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    #conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_ch, out_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=3, stride=1, padding=1)  # 7 x 7\n",
    "        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)  # 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_chan, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): # -> 28 x 28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvolutionalAutoEncoder(nn.Module): # Сверточный автоэнкодер\n",
    "    def __init__(self, input_ch, enc_hidden_ch, dec_hidden_ch, latent_ch):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_ch, enc_hidden_ch, latent_ch)\n",
    "        self.decoder = Decoder(latent_ch, dec_hidden_ch, input_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n",
    "\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79be8a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 0\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 1\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 2\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 3\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 4\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 5\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 6\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 7\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 8\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 9\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 10\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 11\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 12\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 13\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 14\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 15\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 16\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 17\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 18\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch: 19\n"
     ]
    }
   ],
   "source": [
    "model2 = ConvolutionalAutoEncoder(1, 20, 20, 1)\n",
    "model2.train()\n",
    "model2.to(device)\n",
    "\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.MNIST('C:\\\\Users\\\\Vampire\\\\Repos\\\\NN_reload_stream2', download=False)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "#dataloder\n",
    "#предварительный вывод: использование сигмоиды позволяет  обойтись меньшим числом кодируемых каналов\n",
    "for epoch in range(num_epoch):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim.zero_grad()\n",
    "        predict = model2(data)\n",
    "        loss = loss_func(predict, data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print(loss)\n",
    "    print(f'epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c64c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33676\n"
     ]
    }
   ],
   "source": [
    "#dataset.data[768].unsqueeze(0).unsqueeze(0).float()/255\n",
    "with torch.no_grad():\n",
    "    model2.eval()\n",
    "    test = dataset.data[255].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "    test = test.to(device)\n",
    "    #print(test.device)\n",
    "    predict = model2(test)\n",
    "    test = test[0].view(28, 28).detach().cpu().numpy()\n",
    "    print((test*255).astype(int).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c59891f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 20\n",
    "cuda_device = -1\n",
    "batch_size = 256\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#model\n",
    "\n",
    "\n",
    "# conv autoencoder\n",
    "#model\n",
    "# conv autoencoder\n",
    "class Encoder(nn.Module):\n",
    "    # 28*28 -> hidden -> out\n",
    "    def __init__(self, in_chan, hidden_ch, out_channels):\n",
    "        super().__init__()\n",
    "        #conv2d -> maxpool2d -> conv2d -> maxpool2d -> conv2d\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=5, stride=1, padding=2) # 28 x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 7 x 7\n",
    "        self.conv_mu = nn.Conv2d(hidden_ch, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_sigma = nn.Conv2d(hidden_ch, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): # -> 7x7\n",
    "        x = self.activation(self.pool1(self.conv1(x)))\n",
    "        x = self.activation(self.pool2(self.conv2(x)))\n",
    "        mu = self.activation(self.conv_mu(x))\n",
    "        sigma = torch.exp(self.conv_sigma(x))\n",
    "\n",
    "        return mu, sigma\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    #conv2d -> upsampling2d -> conv2d -> upsampling2d -> conv2d\n",
    "    def __init__(self, in_chan, hidden_ch, out_chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, hidden_ch, kernel_size=3, stride=1, padding=1)  # 7 x 7\n",
    "        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)  # 14 x 14\n",
    "        self.conv2 = nn.Conv2d(hidden_ch, hidden_ch, kernel_size=3, stride=1, padding=1)  # 14 x 14\n",
    "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)  # 28 x 28\n",
    "        self.conv3 = nn.Conv2d(hidden_ch, out_chan, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): # -> 28 x 28\n",
    "        x = self.activation(self.upsample1(self.conv1(x)))\n",
    "        x = self.activation(self.upsample2(self.conv2(x)))\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VarAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_ch, enc_hidden_ch, dec_hidden_ch, latent_ch):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_ch, enc_hidden_ch, latent_ch)\n",
    "        self.decoder = Decoder(latent_ch, dec_hidden_ch, input_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        x = sampling(mu, sigma)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x, mu, sigma\n",
    "\n",
    "\n",
    "# sampling\n",
    "def sampling(mu, sigma):\n",
    "    return mu + sigma * torch.normal(torch.zeros_like(sigma),\n",
    "                                     torch.ones_like(sigma))\n",
    "\n",
    "\n",
    "def kl_loss(mu, sigma):\n",
    "    p = torch.distributions.Normal(mu, sigma)\n",
    "    q = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(sigma))\n",
    "\n",
    "    return torch.distributions.kl_divergence(p, q).mean()\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    target = []\n",
    "    for item in data:\n",
    "\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        target.append(item[1])\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)).float() / 255,\n",
    "        'target': torch.from_numpy(numpy.array(target)),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89c4f44d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl_loss: 0.13293519616127014, criterion_loss: 0.1522369533777237\n",
      "kl_loss: 0.0033520690631121397, criterion_loss: 0.0962066799402237\n",
      "kl_loss: 0.0013229588512331247, criterion_loss: 0.09411144256591797\n",
      "epoch: 0\n",
      "kl_loss: 0.00106586585752666, criterion_loss: 0.09338672459125519\n",
      "kl_loss: 0.0006364218425005674, criterion_loss: 0.08759849518537521\n",
      "kl_loss: 0.0004244714218657464, criterion_loss: 0.08645078539848328\n",
      "epoch: 1\n",
      "kl_loss: 0.00037854776019230485, criterion_loss: 0.08318693935871124\n",
      "kl_loss: 0.0002758192422334105, criterion_loss: 0.08384966105222702\n",
      "kl_loss: 0.00021264978568069637, criterion_loss: 0.08185949921607971\n",
      "epoch: 2\n",
      "kl_loss: 0.0001960845256689936, criterion_loss: 0.08247560262680054\n",
      "kl_loss: 0.00016001630865503103, criterion_loss: 0.08144066482782364\n",
      "kl_loss: 0.0001333380932919681, criterion_loss: 0.07883244007825851\n",
      "epoch: 3\n",
      "kl_loss: 0.00012725178385153413, criterion_loss: 0.07908649742603302\n",
      "kl_loss: 0.00011334777082083747, criterion_loss: 0.08112414181232452\n",
      "kl_loss: 9.648355626268312e-05, criterion_loss: 0.07960595935583115\n",
      "epoch: 4\n",
      "kl_loss: 0.00010056154133053496, criterion_loss: 0.08028492331504822\n",
      "kl_loss: 8.705368236405775e-05, criterion_loss: 0.07928266376256943\n",
      "kl_loss: 9.300141391577199e-05, criterion_loss: 0.07934276759624481\n",
      "epoch: 5\n",
      "kl_loss: 0.00011510678450576961, criterion_loss: 0.07838234305381775\n",
      "kl_loss: 0.0001350430102320388, criterion_loss: 0.08093860000371933\n",
      "kl_loss: 0.00014501536497846246, criterion_loss: 0.08071988075971603\n",
      "epoch: 6\n",
      "kl_loss: 0.00020773753931280226, criterion_loss: 0.07932653278112411\n",
      "kl_loss: 0.0002723589714150876, criterion_loss: 0.08087035268545151\n",
      "kl_loss: 0.00040321462438441813, criterion_loss: 0.0809924453496933\n",
      "epoch: 7\n",
      "kl_loss: 0.0004508883284870535, criterion_loss: 0.07920810580253601\n",
      "kl_loss: 0.0007471399731002748, criterion_loss: 0.07780574262142181\n",
      "kl_loss: 0.0009964612545445561, criterion_loss: 0.080343097448349\n",
      "epoch: 8\n",
      "kl_loss: 0.0011491867480799556, criterion_loss: 0.07935880124568939\n",
      "kl_loss: 0.0015827447641640902, criterion_loss: 0.07984167337417603\n",
      "kl_loss: 0.0021883747540414333, criterion_loss: 0.07964860647916794\n",
      "epoch: 9\n",
      "kl_loss: 0.0021778244990855455, criterion_loss: 0.07715950906276703\n",
      "kl_loss: 0.0031215730123221874, criterion_loss: 0.07703635841608047\n",
      "kl_loss: 0.004213021136820316, criterion_loss: 0.08001433312892914\n",
      "epoch: 10\n",
      "kl_loss: 0.004312047269195318, criterion_loss: 0.07690839469432831\n",
      "kl_loss: 0.005327682010829449, criterion_loss: 0.07814217358827591\n",
      "kl_loss: 0.006462076213210821, criterion_loss: 0.07658368349075317\n",
      "epoch: 11\n",
      "kl_loss: 0.007504068315029144, criterion_loss: 0.07910117506980896\n",
      "kl_loss: 0.009175854735076427, criterion_loss: 0.07533972710371017\n",
      "kl_loss: 0.011083354242146015, criterion_loss: 0.07644421607255936\n",
      "epoch: 12\n",
      "kl_loss: 0.012603533454239368, criterion_loss: 0.07830160111188889\n",
      "kl_loss: 0.014767106622457504, criterion_loss: 0.07633523643016815\n",
      "kl_loss: 0.019061576575040817, criterion_loss: 0.07575336843729019\n",
      "epoch: 13\n",
      "kl_loss: 0.018940381705760956, criterion_loss: 0.07524953782558441\n",
      "kl_loss: 0.022112825885415077, criterion_loss: 0.0752098485827446\n",
      "kl_loss: 0.027296725660562515, criterion_loss: 0.07424389570951462\n",
      "epoch: 14\n",
      "kl_loss: 0.02610643580555916, criterion_loss: 0.07299813628196716\n",
      "kl_loss: 0.033628810197114944, criterion_loss: 0.07346846163272858\n",
      "kl_loss: 0.03461041301488876, criterion_loss: 0.07140596210956573\n",
      "epoch: 15\n",
      "kl_loss: 0.03736430034041405, criterion_loss: 0.0732717290520668\n",
      "kl_loss: 0.03965205326676369, criterion_loss: 0.0724211186170578\n",
      "kl_loss: 0.04167463257908821, criterion_loss: 0.07094518095254898\n",
      "epoch: 16\n",
      "kl_loss: 0.04536847770214081, criterion_loss: 0.07205032557249069\n",
      "kl_loss: 0.04415297880768776, criterion_loss: 0.07009614259004593\n",
      "kl_loss: 0.04949932545423508, criterion_loss: 0.07149481773376465\n",
      "epoch: 17\n",
      "kl_loss: 0.04772908240556717, criterion_loss: 0.07146548479795456\n",
      "kl_loss: 0.05320911854505539, criterion_loss: 0.07163938879966736\n",
      "kl_loss: 0.052897900342941284, criterion_loss: 0.0710086077451706\n",
      "epoch: 18\n",
      "kl_loss: 0.05216342955827713, criterion_loss: 0.06845342367887497\n",
      "kl_loss: 0.05144474282860756, criterion_loss: 0.06786227226257324\n",
      "kl_loss: 0.05447937920689583, criterion_loss: 0.06922462582588196\n",
      "epoch: 19\n"
     ]
    }
   ],
   "source": [
    "model3 = VarAutoEncoder(1, 10, 10, 1)\n",
    "model3.train()\n",
    "model3.to(device)\n",
    "# result = model(test_tersor)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
    "#lr scheduler\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('C:\\\\Users\\\\Vampire\\\\Repos\\\\NN_reload_stream2', download=False)\n",
    "\n",
    "#\n",
    "#loss\n",
    "criterion = nn.MSELoss()\n",
    "#dataloder\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch['data'].to(device).unsqueeze(1)\n",
    "        optim.zero_grad()\n",
    "        predict, mu, sigma = model3(data)\n",
    "        #loss\n",
    "        kl = kl_loss(mu, sigma)\n",
    "        crit_loss = criterion(data, predict)\n",
    "        #фактически к ошибке применяется штраф зависящий от посчитанной дивергенции\n",
    "        loss = 0.1 * kl + crit_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (step % 100 == 0):\n",
    "            print('kl_loss: {}, criterion_loss: {}'.format(kl.item(), crit_loss.item()))\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test = dataset.data[768].float() #.to(device)\n",
    "    print(test.size())\n",
    "    #predict = model(test)\n",
    "    \n",
    "    #encoded_mu, encoded_sigma = model.encoder(test)\n",
    "    #hidden = sampling(encoded_mu, encoded_sigma)\n",
    "    #hidden += torch.ones_like(hidden) * 0.1\n",
    "    #decoded = model.decoder(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee9ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdec82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33676\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model3.eval()\n",
    "    test = dataset.data[255].unsqueeze(0).unsqueeze(0).float() / 255\n",
    "    test = test.to(device)\n",
    "    #print(test.device)\n",
    "    predict = model3(test)\n",
    "    test = test[0].view(28, 28).detach().cpu().numpy()\n",
    "    print((test*255).astype(int).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba3fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
