{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0f4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy \n",
    "import numpy as np\n",
    "\n",
    "#hyper params\n",
    "num_epoch = 20\n",
    "cuda_device = 1\n",
    "batch_size = 140\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "input_d = 28*28\n",
    "hidden_d = 512\n",
    "out_d = 10\n",
    "\n",
    "#model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, out_dim: int,):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.linear3 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "        #self\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.activation(self.linear2(x))\n",
    "        x = self.activation(self.linear3(x)) #activation(self.linear3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(data): ##\n",
    "    pics = []\n",
    "    targets = []\n",
    "    # data = [(pic, target), ....]\n",
    "    for item in data:\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        targets.append(item[1])\n",
    "\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)) / 255,\n",
    "        'target': torch.from_numpy(numpy.array(targets))\n",
    "    }\n",
    "\n",
    "\n",
    "# init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ce0a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be26667d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "tensor(2.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4635, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "model = MyModel(input_d, hidden_d, out_d)\n",
    "model = model.to(device)\n",
    "\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#lr scheduler\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('C:\\\\Users\\\\Vampire\\\\Repos\\\\NN_reload_stream2', download=True)\n",
    "\n",
    "train_dataset = dataset\n",
    "valid_dataset = dataset\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(0.2 * dataset_size))\n",
    "\n",
    "\n",
    "shuffle=True\n",
    "random_seed = 42\n",
    "if shuffle == True:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "print(len(train_idx), len(valid_idx))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train loop\n",
    "for epoch in range(num_epoch):\n",
    "    #dataloder\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             #shuffle=True,\n",
    "                             collate_fn=collate_fn,\n",
    "                             drop_last=True, sampler = train_sampler\n",
    "                             )\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        optim.zero_grad()\n",
    "        data = batch['data'].to(device).float()\n",
    "        predict = model(data.view(data.size(0), -1))\n",
    "        \n",
    "        loss = criterion(predict, batch['target'].long().to(device))\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optim.step()\n",
    "        if (i % 100) == 0:\n",
    "            print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834201ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4705, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dataset.data[0].detach().numpy())\n",
    "print(type(dataset.data[0]))\n",
    "plt.show()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee12ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(collate_fn(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094163c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe86179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vampire\\AppData\\Local\\Temp\\ipykernel_12720\\3577221052.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = torch.tensor(I/255).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.6762e-10, 5.8112e-06, 6.6877e-09, 1.0000e+00, 6.6071e-16, 2.5134e-07,\n",
       "         1.3398e-18, 5.4522e-11, 3.2390e-08, 3.8766e-08]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_one_image(I, model):\n",
    "    '''\n",
    "    I - 28x28 uint8 numpy array\n",
    "    '''\n",
    "    model.eval()\n",
    "    #print(torch.tensor(I/255).size())\n",
    "    batch = torch.tensor(I/255).unsqueeze(0)\n",
    "    #print(batch.size())\n",
    "    batch = batch.view(batch.size(0), -1)\n",
    "    #print(batch.size()) \n",
    "    with torch.no_grad():\n",
    "        batch = batch.to(device)\n",
    "        output = model( batch )\n",
    "        #output = torch.argmax(output, 1)\n",
    "    return output\n",
    "\n",
    "index = 255\n",
    "item = dataset[index]\n",
    "\n",
    "image = torch.from_numpy(numpy.array(item[0])) \n",
    "\n",
    "test_one_image(image, model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c522f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vampire\\AppData\\Local\\Temp\\ipykernel_12720\\887067205.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  plt.imshow(torch.tensor(image).clone().detach().numpy())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.tensor(image).clone().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb896ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = DataLoader(\n",
    "                                 dataset=dataset,\n",
    "                                 batch_size=12000,\n",
    "                                 #shuffle=True,\n",
    "                                 collate_fn=collate_fn,\n",
    "                                 drop_last=True, sampler = test_sampler\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef024f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4842, device='cuda:0') 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4842, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(data_loader_test):\n",
    "        data = batch['data'].to(device).float()\n",
    "        predict = model(data.view(data.size(0), -1))\n",
    "        loss = criterion(predict, batch['target'].long().to(device))\n",
    "        #loss.backward()\n",
    "        #print(loss)\n",
    "        #optim.step()\n",
    "        if (i % 100) == 0:\n",
    "            print(loss, i)\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a699e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vampire\\AppData\\Local\\Temp\\ipykernel_12720\\3577221052.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = torch.tensor(I/255).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7.6687e-09, 1.8417e-08, 2.3209e-11, 1.9339e-07, 1.4665e-13, 3.0127e-08,\n",
       "         3.5859e-21, 1.0000e+00, 9.2704e-13, 5.6125e-04]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = valid_idx[0]\n",
    "item = dataset[index]\n",
    "\n",
    "image = torch.from_numpy(numpy.array(item[0])) \n",
    "\n",
    "test_one_image(image, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d031aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vampire\\AppData\\Local\\Temp\\ipykernel_12720\\887067205.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  plt.imshow(torch.tensor(image).clone().detach().numpy())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.tensor(image).clone().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c26587a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сверточные\n",
    "import torch.nn.functional as fun\n",
    "num_epoch = 20\n",
    "cuda_device = -1\n",
    "batch_size = 140\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "input_ch = 1\n",
    "hidden_ch = 256\n",
    "hidden_neurons = 768\n",
    "hidden_neurons1 = 512\n",
    "out_d = 10\n",
    "\n",
    "#model\n",
    "class MyModelCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 hidden_channels: int,\n",
    "                 n_classes: int,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # TODO change architecture\n",
    "        # TODO use pooling\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=5, padding=2, stride=2) # 14 * 14\n",
    "        # TODO add batchnorm after each conv\n",
    "        self.conv1_bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2_bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, 1, kernel_size=1, padding=0, stride=1)\n",
    "        self.conv3_bn3 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.linear1 = nn.Linear(14*14, hidden_neurons, bias=True)\n",
    "        self.linear2 = nn.Linear(hidden_neurons, hidden_neurons1, bias=True)\n",
    "        self.linear3 = nn.Linear(hidden_neurons1, n_classes, bias = True)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.conv1_bn1(x)\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.conv2_bn2(x)\n",
    "        x = self.activation(self.conv3(x))\n",
    "        #x = self.conv_bn3(x)\n",
    "        x = self.activation(self.linear1(x.view(x.size(0), -1)))\n",
    "        x = self.activation(self.linear2(x))\n",
    "        x = self.activation(self.linear3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    pics = []\n",
    "    targets = []\n",
    "    # data = [(pic, target), ....]\n",
    "    for item in data:\n",
    "        pics.append(numpy.array(item[0]))\n",
    "        targets.append(item[1])\n",
    "\n",
    "    return {\n",
    "        'data': torch.from_numpy(numpy.array(pics)) / 255,\n",
    "        'target': torch.from_numpy(numpy.array(targets))\n",
    "    }\n",
    "\n",
    "# init model\n",
    "model = MyModelCNN(input_ch, hidden_ch, out_d)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "#optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d8392bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "tensor(2.2912, device='cuda:0', grad_fn=<NllLossBackward0>) 0 0\n",
      "tensor(1.6452, device='cuda:0', grad_fn=<NllLossBackward0>) 0 100\n",
      "tensor(1.5668, device='cuda:0', grad_fn=<NllLossBackward0>) 0 200\n",
      "tensor(1.5009, device='cuda:0', grad_fn=<NllLossBackward0>) 0 300\n",
      "tensor(1.5404, device='cuda:0', grad_fn=<NllLossBackward0>) 1 0\n",
      "tensor(1.5179, device='cuda:0', grad_fn=<NllLossBackward0>) 1 100\n",
      "tensor(1.5101, device='cuda:0', grad_fn=<NllLossBackward0>) 1 200\n",
      "tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward0>) 1 300\n",
      "tensor(1.4828, device='cuda:0', grad_fn=<NllLossBackward0>) 2 0\n",
      "tensor(1.4891, device='cuda:0', grad_fn=<NllLossBackward0>) 2 100\n",
      "tensor(1.5091, device='cuda:0', grad_fn=<NllLossBackward0>) 2 200\n",
      "tensor(1.4859, device='cuda:0', grad_fn=<NllLossBackward0>) 2 300\n",
      "tensor(1.4762, device='cuda:0', grad_fn=<NllLossBackward0>) 3 0\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward0>) 3 100\n",
      "tensor(1.5183, device='cuda:0', grad_fn=<NllLossBackward0>) 3 200\n",
      "tensor(1.4934, device='cuda:0', grad_fn=<NllLossBackward0>) 3 300\n",
      "tensor(1.4797, device='cuda:0', grad_fn=<NllLossBackward0>) 4 0\n",
      "tensor(1.4975, device='cuda:0', grad_fn=<NllLossBackward0>) 4 100\n",
      "tensor(1.4807, device='cuda:0', grad_fn=<NllLossBackward0>) 4 200\n",
      "tensor(1.4736, device='cuda:0', grad_fn=<NllLossBackward0>) 4 300\n",
      "tensor(1.4831, device='cuda:0', grad_fn=<NllLossBackward0>) 5 0\n",
      "tensor(1.4701, device='cuda:0', grad_fn=<NllLossBackward0>) 5 100\n",
      "tensor(1.4836, device='cuda:0', grad_fn=<NllLossBackward0>) 5 200\n",
      "tensor(1.4779, device='cuda:0', grad_fn=<NllLossBackward0>) 5 300\n",
      "tensor(1.4825, device='cuda:0', grad_fn=<NllLossBackward0>) 6 0\n",
      "tensor(1.4687, device='cuda:0', grad_fn=<NllLossBackward0>) 6 100\n",
      "tensor(1.4763, device='cuda:0', grad_fn=<NllLossBackward0>) 6 200\n",
      "tensor(1.4786, device='cuda:0', grad_fn=<NllLossBackward0>) 6 300\n",
      "tensor(1.4713, device='cuda:0', grad_fn=<NllLossBackward0>) 7 0\n",
      "tensor(1.4886, device='cuda:0', grad_fn=<NllLossBackward0>) 7 100\n",
      "tensor(1.4644, device='cuda:0', grad_fn=<NllLossBackward0>) 7 200\n",
      "tensor(1.4765, device='cuda:0', grad_fn=<NllLossBackward0>) 7 300\n",
      "tensor(1.4796, device='cuda:0', grad_fn=<NllLossBackward0>) 8 0\n",
      "tensor(1.4790, device='cuda:0', grad_fn=<NllLossBackward0>) 8 100\n",
      "tensor(1.4778, device='cuda:0', grad_fn=<NllLossBackward0>) 8 200\n",
      "tensor(1.4724, device='cuda:0', grad_fn=<NllLossBackward0>) 8 300\n",
      "tensor(1.4895, device='cuda:0', grad_fn=<NllLossBackward0>) 9 0\n",
      "tensor(1.4750, device='cuda:0', grad_fn=<NllLossBackward0>) 9 100\n",
      "tensor(1.4696, device='cuda:0', grad_fn=<NllLossBackward0>) 9 200\n",
      "tensor(1.4920, device='cuda:0', grad_fn=<NllLossBackward0>) 9 300\n",
      "tensor(1.4783, device='cuda:0', grad_fn=<NllLossBackward0>) 10 0\n",
      "tensor(1.4669, device='cuda:0', grad_fn=<NllLossBackward0>) 10 100\n",
      "tensor(1.4650, device='cuda:0', grad_fn=<NllLossBackward0>) 10 200\n",
      "tensor(1.4806, device='cuda:0', grad_fn=<NllLossBackward0>) 10 300\n",
      "tensor(1.4852, device='cuda:0', grad_fn=<NllLossBackward0>) 11 0\n",
      "tensor(1.4797, device='cuda:0', grad_fn=<NllLossBackward0>) 11 100\n",
      "tensor(1.4675, device='cuda:0', grad_fn=<NllLossBackward0>) 11 200\n",
      "tensor(1.4710, device='cuda:0', grad_fn=<NllLossBackward0>) 11 300\n",
      "tensor(1.4680, device='cuda:0', grad_fn=<NllLossBackward0>) 12 0\n",
      "tensor(1.4662, device='cuda:0', grad_fn=<NllLossBackward0>) 12 100\n",
      "tensor(1.4737, device='cuda:0', grad_fn=<NllLossBackward0>) 12 200\n",
      "tensor(1.4768, device='cuda:0', grad_fn=<NllLossBackward0>) 12 300\n",
      "tensor(1.4729, device='cuda:0', grad_fn=<NllLossBackward0>) 13 0\n",
      "tensor(1.4728, device='cuda:0', grad_fn=<NllLossBackward0>) 13 100\n",
      "tensor(1.4700, device='cuda:0', grad_fn=<NllLossBackward0>) 13 200\n",
      "tensor(1.4682, device='cuda:0', grad_fn=<NllLossBackward0>) 13 300\n",
      "tensor(1.4796, device='cuda:0', grad_fn=<NllLossBackward0>) 14 0\n",
      "tensor(1.4789, device='cuda:0', grad_fn=<NllLossBackward0>) 14 100\n",
      "tensor(1.4720, device='cuda:0', grad_fn=<NllLossBackward0>) 14 200\n",
      "tensor(1.4714, device='cuda:0', grad_fn=<NllLossBackward0>) 14 300\n",
      "tensor(1.4676, device='cuda:0', grad_fn=<NllLossBackward0>) 15 0\n",
      "tensor(1.4684, device='cuda:0', grad_fn=<NllLossBackward0>) 15 100\n",
      "tensor(1.4649, device='cuda:0', grad_fn=<NllLossBackward0>) 15 200\n",
      "tensor(1.4625, device='cuda:0', grad_fn=<NllLossBackward0>) 15 300\n",
      "tensor(1.4824, device='cuda:0', grad_fn=<NllLossBackward0>) 16 0\n",
      "tensor(1.4742, device='cuda:0', grad_fn=<NllLossBackward0>) 16 100\n",
      "tensor(1.4733, device='cuda:0', grad_fn=<NllLossBackward0>) 16 200\n",
      "tensor(1.4699, device='cuda:0', grad_fn=<NllLossBackward0>) 16 300\n",
      "tensor(1.4652, device='cuda:0', grad_fn=<NllLossBackward0>) 17 0\n",
      "tensor(1.4845, device='cuda:0', grad_fn=<NllLossBackward0>) 17 100\n",
      "tensor(1.4771, device='cuda:0', grad_fn=<NllLossBackward0>) 17 200\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward0>) 17 300\n",
      "tensor(1.4642, device='cuda:0', grad_fn=<NllLossBackward0>) 18 0\n",
      "tensor(1.4715, device='cuda:0', grad_fn=<NllLossBackward0>) 18 100\n",
      "tensor(1.4669, device='cuda:0', grad_fn=<NllLossBackward0>) 18 200\n",
      "tensor(1.4768, device='cuda:0', grad_fn=<NllLossBackward0>) 18 300\n",
      "tensor(1.4684, device='cuda:0', grad_fn=<NllLossBackward0>) 19 0\n",
      "tensor(1.4760, device='cuda:0', grad_fn=<NllLossBackward0>) 19 100\n",
      "tensor(1.4632, device='cuda:0', grad_fn=<NllLossBackward0>) 19 200\n",
      "tensor(1.4711, device='cuda:0', grad_fn=<NllLossBackward0>) 19 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#lr scheduler\n",
    "\n",
    "#dataset\n",
    "dataset = datasets.MNIST('/Users/Vampire/Repos/NN_reload_stream2', download=False)\n",
    "\n",
    "train_dataset = dataset\n",
    "valid_dataset = dataset\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(0.2 * dataset_size))\n",
    "\n",
    "\n",
    "shuffle=True\n",
    "random_seed = 42\n",
    "if shuffle == True:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "print(len(train_idx), len(valid_idx))\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train loop\n",
    "for epoch in range(num_epoch):\n",
    "    #dataloder\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             #shuffle=True,\n",
    "                             collate_fn=collate_fn,\n",
    "                             drop_last=True, sampler = train_sampler\n",
    "                             )\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        optim.zero_grad()\n",
    "        data = batch['data'].to(device).float()\n",
    "        predict = model(data.unsqueeze(1))\n",
    "        loss = criterion(predict, batch['target'].long().to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if (i % 100) == 0:\n",
    "            print(loss, epoch,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bae7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4697, device='cuda:0') 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4736, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test = DataLoader(\n",
    "                                 dataset=dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 #shuffle=True,\n",
    "                                 collate_fn=collate_fn,\n",
    "                                 drop_last=True, sampler = test_sampler\n",
    "                             )\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(data_loader_test):\n",
    "        data = batch['data'].to(device).float()\n",
    "        predict = model(data.unsqueeze(1))\n",
    "        loss = criterion(predict, batch['target'].long().to(device))\n",
    "        #loss.backward()\n",
    "        #print(loss)\n",
    "        #optim.step()\n",
    "        if (i % 100) == 0:\n",
    "            print(loss, i)\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b68a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20078a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85079d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ea7259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4854002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9684669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
